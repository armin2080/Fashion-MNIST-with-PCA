{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **Exploring PCA and Random Forest: Fashion MNIST Classification**\n",
    "\n",
    "This project demonstrates the application of Principal Component Analysis (PCA) and Random Forest Classification on the Fashion MNIST dataset. The goal is to explore the effect of dimensionality reduction on model performance in terms of accuracy and computational time.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Importing Required Libraries**\n",
    "\n",
    "This cell imports the necessary libraries for the project, including TensorFlow's Fashion MNIST dataset, visualization tools like Matplotlib, and machine learning utilities from Scikit-learn. These libraries will be used for data preprocessing, dimensionality reduction, and model evaluation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.datasets import fashion_mnist\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA\n",
    "import numpy as np\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Loading the Dataset**\n",
    "\n",
    "This cell loads the Fashion MNIST dataset, splitting it into training and testing sets. The shapes of the data arrays are printed to provide an overview of the dataset dimensions:\n",
    "\n",
    "- `x_train` and `x_test` contain the image data.\n",
    "- `y_train` and `y_test` contain the corresponding labels.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the dataset\n",
    "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
    "\n",
    "# Print the shape of the data\n",
    "print(f\"x_train shape: {x_train.shape}\")\n",
    "print(f\"x_test shape: {x_test.shape}\")\n",
    "print(f\"y_train shape: {y_train.shape}\")\n",
    "print(f\"y_test shape: {y_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Visualizing the Dataset**\n",
    "\n",
    "This cell defines and uses a function `plot_sample_images` to display a grid of 5x5 images from the training dataset along with their corresponding labels. It provides a visual understanding of the data:\n",
    "\n",
    "- Each image is shown in grayscale with its label displayed as the title.\n",
    "- The function creates a subplot grid for better organization and layout.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display a grid of 5x5 images\n",
    "def plot_sample_images(x, y, n=5):\n",
    "    fig, axes = plt.subplots(n, n, figsize=(10, 10))\n",
    "    axes = axes.ravel()  # Flatten the grid of axes\n",
    "    for i in range(n * n):\n",
    "        axes[i].imshow(x[i], cmap='gray')\n",
    "        axes[i].set_title(f\"Label: {y[i]}\")\n",
    "        axes[i].axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Show sample images from the training set\n",
    "plot_sample_images(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Flattening the Images**\n",
    "\n",
    "In this step, the images from the training and test sets are flattened from 28x28 pixel arrays into 1-dimensional vectors of 784 pixels. Flattening is necessary for feeding the data into machine learning models such as Random Forest.\n",
    "\n",
    "- `x_train_flattened` and `x_test_flattened` store the reshaped arrays.\n",
    "- The shapes of the reshaped arrays are printed to confirm the successful transformation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Flatten the images\n",
    "x_train_flattened = x_train.reshape(x_train.shape[0], -1)\n",
    "x_test_flattened = x_test.reshape(x_test.shape[0], -1)\n",
    "\n",
    "# Check the shapes\n",
    "print(f\"x_train_flattened shape: {x_train_flattened.shape}\")\n",
    "print(f\"x_test_flattened shape: {x_test_flattened.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Applying PCA for Dimensionality Reduction**\n",
    "\n",
    "In this step, Principal Component Analysis (PCA) is used to reduce the dimensionality of the flattened images, keeping most of the variance in the data.\n",
    "\n",
    "1. First, the PCA model is fit on the training data (`x_train_flattened`).\n",
    "2. The cumulative explained variance ratio is plotted to show how much variance is captured by the principal components.\n",
    "3. Based on the plot, the number of components is selected to retain 95% of the variance (`n_components=0.95`).\n",
    "4. The training and test data are transformed into the reduced-dimensionality space.\n",
    "5. Finally, the new shapes of the transformed training and test data are printed, reflecting the reduced number of features after PCA.\n",
    "\n",
    "The choice of 95% variance retention ensures a balance between reducing dimensionality and preserving important information in the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize PCA and fit it on the training data\n",
    "pca = PCA()\n",
    "pca.fit(x_train_flattened)\n",
    "\n",
    "# Plot the explained variance ratio\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.plot(range(1, 785), np.cumsum(pca.explained_variance_ratio_), marker='o')\n",
    "plt.title('Explained Variance by Number of Components')\n",
    "plt.xlabel('Number of Principal Components')\n",
    "plt.ylabel('Cumulative Explained Variance')\n",
    "plt.grid(True)\n",
    "plt.show()\n",
    "\n",
    "# You can choose the number of components based on the explained variance.\n",
    "# For example, let's choose the number of components to retain 95% of the variance.\n",
    "pca = PCA(n_components=0.95)\n",
    "x_train_pca = pca.fit_transform(x_train_flattened)\n",
    "x_test_pca = pca.transform(x_test_flattened)\n",
    "\n",
    "# Print the new shape after applying PCA\n",
    "print(f\"x_train_pca shape: {x_train_pca.shape}\")\n",
    "print(f\"x_test_pca shape: {x_test_pca.shape}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Evaluating the Effect of PCA on Model Performance and Training Time**\n",
    "\n",
    "In this step, we evaluate the impact of different numbers of principal components on both the accuracy and the training time of the model.\n",
    "\n",
    "1. A list of potential component sizes (`components_list`) is defined to test.\n",
    "2. For each number of components in the list, the following steps are executed:\n",
    "   - PCA is applied to reduce the dimensionality of the data.\n",
    "   - A Random Forest classifier is trained using the transformed training data (`x_train_pca`).\n",
    "   - The training time is measured using the `time` library to capture how long the model takes to fit and make predictions.\n",
    "   - The accuracy of the model is calculated using `accuracy_score`.\n",
    "3. The accuracy and time taken for each number of components are recorded in `accuracy_list` and `time_list`.\n",
    "4. Finally, two plots are generated:\n",
    "   - **Accuracy vs. Number of Principal Components**: Shows how accuracy changes with the number of components.\n",
    "   - **Time Taken vs. Number of Principal Components**: Shows how the model's training time changes as more components are included.\n",
    "\n",
    "This comparison helps in selecting an optimal number of components based on a trade-off between model performance and computational time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of components to test\n",
    "components_list = [50, 100, 150, 200, 300, 400, 500]\n",
    "\n",
    "# Store the results\n",
    "accuracy_list = []\n",
    "time_list = []\n",
    "\n",
    "for n_components in components_list:\n",
    "    # Apply PCA with n_components\n",
    "    pca = PCA(n_components=n_components)\n",
    "    x_train_pca = pca.fit_transform(x_train_flattened)\n",
    "    x_test_pca = pca.transform(x_test_flattened)\n",
    "    \n",
    "    # Train Random Forest model\n",
    "    model = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "    \n",
    "    # Time the training and prediction\n",
    "    start_time = time.time()\n",
    "    model.fit(x_train_pca, y_train)\n",
    "    end_time = time.time()\n",
    "    \n",
    "    # Get the accuracy\n",
    "    y_pred = model.predict(x_test_pca)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # Append results\n",
    "    accuracy_list.append(accuracy)\n",
    "    time_list.append(end_time - start_time)\n",
    "\n",
    "# Plot the accuracy vs. number of components\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(components_list, accuracy_list, marker='o')\n",
    "plt.title('Accuracy vs. Number of Principal Components')\n",
    "plt.xlabel('Number of Principal Components')\n",
    "plt.ylabel('Accuracy')\n",
    "\n",
    "# Plot the time taken vs. number of components\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(components_list, time_list, marker='o', color='r')\n",
    "plt.title('Time Taken vs. Number of Principal Components')\n",
    "plt.xlabel('Number of Principal Components')\n",
    "plt.ylabel('Time Taken (seconds)')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Model Training and Evaluation with PCA**\n",
    "\n",
    "In this step, we train the Random Forest classifier on the PCA-transformed training data and evaluate its performance:\n",
    "\n",
    "1. **Timer Start**: The training time is measured using `time.time()` to calculate the time taken for both training and prediction.\n",
    "2. **Model Initialization**: A Random Forest classifier (`rf`) is initialized with 50 estimators and a fixed random state for reproducibility.\n",
    "3. **Model Training**: The model is trained using the PCA-transformed training data (`x_train_pca`).\n",
    "4. **Prediction**: The model makes predictions on the PCA-transformed test data (`x_test_pca`).\n",
    "5. **Accuracy Calculation**: The accuracy of the model is computed by comparing the predicted labels (`y_pred_pca`) with the true labels (`y_test`).\n",
    "6. **Timer End**: The end time is recorded, and the total time for training and prediction is calculated by subtracting the start time from the end time.\n",
    "7. **Results**: Finally, the accuracy and time taken for training and prediction are printed.\n",
    "\n",
    "This step allows for the evaluation of the model's performance and the computational time required after applying PCA for dimensionality reduction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the timer\n",
    "start_time = time.time()\n",
    "\n",
    "# Initialize the Random Forest classifier\n",
    "rf = RandomForestClassifier(n_estimators=50, random_state=42)\n",
    "\n",
    "# Train the model on the PCA-transformed training data\n",
    "rf.fit(x_train_pca, y_train)\n",
    "\n",
    "# Predict on the PCA-transformed test data\n",
    "y_pred_pca = rf.predict(x_test_pca)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_pca = accuracy_score(y_test, y_pred_pca)\n",
    "\n",
    "# End the timer\n",
    "end_time = time.time()\n",
    "\n",
    "# Calculate the time taken for training and prediction\n",
    "time_taken = end_time - start_time\n",
    "\n",
    "# Print the results\n",
    "print(f\"Accuracy with PCA: {accuracy_pca:.4f}\")\n",
    "print(f\"Time taken with PCA: {time_taken:.4f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Model Training and Evaluation without PCA**\n",
    "\n",
    "In this step, we train the Random Forest classifier on the original data without applying PCA and evaluate its performance:\n",
    "\n",
    "1. **Timer Start**: The training time is measured using `time.time()` to calculate the time taken for both training and prediction without PCA.\n",
    "2. **Model Initialization**: A Random Forest classifier (`rf_no_pca`) is initialized with 100 estimators and a fixed random state for reproducibility.\n",
    "3. **Model Training**: The model is trained using the flattened training data (`x_train_flattened`), which has not undergone PCA transformation.\n",
    "4. **Prediction**: The model makes predictions on the original test data (`x_test_flattened`), which is also not PCA-transformed.\n",
    "5. **Accuracy Calculation**: The accuracy of the model is computed by comparing the predicted labels (`y_pred_no_pca`) with the true labels (`y_test`).\n",
    "6. **Timer End**: The end time is recorded, and the total time for training and prediction is calculated by subtracting the start time from the end time.\n",
    "7. **Results**: Finally, the accuracy and time taken for training and prediction without PCA are printed.\n",
    "\n",
    "This step provides insights into how the model performs without dimensionality reduction and helps compare the impact of PCA on training time and accuracy.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start the timer for training and prediction without PCA\n",
    "start_time_no_pca = time.time()\n",
    "\n",
    "# Train the model on the original data (no PCA)\n",
    "rf_no_pca = RandomForestClassifier(n_estimators=100, random_state=42)\n",
    "rf_no_pca.fit(x_train_flattened, y_train)\n",
    "\n",
    "# Predict on the test data (no PCA)\n",
    "y_pred_no_pca = rf_no_pca.predict(x_test_flattened)\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy_no_pca = accuracy_score(y_test, y_pred_no_pca)\n",
    "\n",
    "# End the timer\n",
    "end_time_no_pca = time.time()\n",
    "\n",
    "# Calculate the time taken for training and prediction (no PCA)\n",
    "time_taken_no_pca = end_time_no_pca - start_time_no_pca\n",
    "\n",
    "# Print the results\n",
    "print(f\"Accuracy without PCA: {accuracy_no_pca:.4f}\")\n",
    "print(f\"Time taken without PCA: {time_taken_no_pca:.4f} seconds\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Model Comparison: With and Without PCA**\n",
    "\n",
    "This section compares the performance of the Random Forest model when trained with and without PCA applied to the data.\n",
    "\n",
    "1. **Results Dictionary**: A dictionary is created to store the accuracy and time taken for both models (with and without PCA). These results were previously calculated.\n",
    "2. **DataFrame Creation**: The results dictionary is converted into a pandas DataFrame for easier presentation and comparison.\n",
    "3. **Display Results**: The comparison DataFrame is printed to the console for a tabular view of the results.\n",
    "4. **Visualization**: A bar plot is generated to visually compare the models' performance:\n",
    "   - **Accuracy Comparison**: A bar plot shows the accuracy for both models, allowing us to visually compare the performance.\n",
    "   - **Time Comparison**: Another bar plot shows the time taken for training and prediction for both models, highlighting the impact of PCA on time efficiency.\n",
    "\n",
    "This step gives a clear overview of how PCA affects the modelâ€™s accuracy and training time.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comparison of models\n",
    "results = {\n",
    "    \"Model\": [\"With PCA\", \"Without PCA\"],\n",
    "    \"Accuracy\": [0.8529, 0.8760],\n",
    "    \"Time Taken (seconds)\": [109.6082, 146.5678]\n",
    "}\n",
    "\n",
    "# Convert to a DataFrame for better presentation\n",
    "import pandas as pd\n",
    "comparison_df = pd.DataFrame(results)\n",
    "\n",
    "# Display the results\n",
    "print(\"Comparison of Models:\")\n",
    "print(comparison_df)\n",
    "\n",
    "# Visualizing the comparison\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot accuracy comparison\n",
    "plt.figure(figsize=(10, 5))\n",
    "\n",
    "# Accuracy Bar Plot\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.bar(results[\"Model\"], results[\"Accuracy\"], color=[\"blue\", \"green\"])\n",
    "plt.title(\"Accuracy Comparison\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.ylim(0.8, 0.9)\n",
    "\n",
    "# Time Taken Bar Plot\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.bar(results[\"Model\"], results[\"Time Taken (seconds)\"], color=[\"blue\", \"green\"])\n",
    "plt.title(\"Time Comparison\")\n",
    "plt.ylabel(\"Time Taken (seconds)\")\n",
    "plt.ylim(100, 160)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
